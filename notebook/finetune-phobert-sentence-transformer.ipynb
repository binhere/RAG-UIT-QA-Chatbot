{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -qU transformers sentence-transformers datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T17:22:16.516134Z","iopub.execute_input":"2025-01-27T17:22:16.516400Z","iopub.status.idle":"2025-01-27T17:22:32.673793Z","shell.execute_reply.started":"2025-01-27T17:22:16.516378Z","shell.execute_reply":"2025-01-27T17:22:32.672497Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict, load_dataset\n\nfrom sentence_transformers import SentenceTransformer, SentenceTransformerTrainer, SentenceTransformerTrainingArguments\nfrom sentence_transformers.training_args import MultiDatasetBatchSamplers\nfrom sentence_transformers.losses import SoftmaxLoss, MultipleNegativesRankingLoss\nfrom sentence_transformers.evaluation import TripletEvaluator, BinaryClassificationEvaluator, SequentialEvaluator\nfrom transformers import EarlyStoppingCallback\n\nimport pandas as pd\nimport numpy as np\nimport random\n\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T17:22:32.675391Z","iopub.execute_input":"2025-01-27T17:22:32.675827Z","iopub.status.idle":"2025-01-27T17:23:05.269530Z","shell.execute_reply.started":"2025-01-27T17:22:32.675788Z","shell.execute_reply":"2025-01-27T17:23:05.268862Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\nsecret_token = user_secrets.get_secret(\"UIT_21520296_DATASET\")\nlogin(token=secret_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T17:23:05.271069Z","iopub.execute_input":"2025-01-27T17:23:05.271656Z","iopub.status.idle":"2025-01-27T17:23:05.551253Z","shell.execute_reply.started":"2025-01-27T17:23:05.271631Z","shell.execute_reply":"2025-01-27T17:23:05.550558Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pair_class_dataset = load_dataset('KhoaUIT/UIT-R2GQA', 'pair-class-segmented')\npair_class_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T17:23:05.552357Z","iopub.execute_input":"2025-01-27T17:23:05.552641Z","iopub.status.idle":"2025-01-27T17:23:08.156164Z","shell.execute_reply.started":"2025-01-27T17:23:05.552607Z","shell.execute_reply":"2025-01-27T17:23:08.155471Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"triplet_dataset = load_dataset('KhoaUIT/UIT-R2GQA', 'triplet-segmented')\ntriplet_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T17:23:08.156937Z","iopub.execute_input":"2025-01-27T17:23:08.157191Z","iopub.status.idle":"2025-01-27T17:23:09.867009Z","shell.execute_reply.started":"2025-01-27T17:23:08.157170Z","shell.execute_reply":"2025-01-27T17:23:09.866311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = {\n    \"pair-class\": pair_class_dataset[\"train\"],\n    \"triplet\": triplet_dataset[\"train\"]\n}\n\neval_dataset={\n    \"pair-class\": pair_class_dataset[\"valid\"],\n    \"triplet\": triplet_dataset[\"valid\"]\n}\n\ntest_dataset={\n    \"pair-class\": pair_class_dataset[\"test\"],\n    \"triplet\": triplet_dataset[\"test\"]\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T17:24:02.823469Z","iopub.execute_input":"2025-01-27T17:24:02.823804Z","iopub.status.idle":"2025-01-27T17:24:02.828043Z","shell.execute_reply.started":"2025-01-27T17:24:02.823778Z","shell.execute_reply":"2025-01-27T17:24:02.827249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load model\n\n\"\"\"\n    Documentation:\n    - Auto truncate any input longer than max_seq_length, see: https://sbert.net/docs/package_reference/sentence_transformer/models.html\n      Notice: \n          + \"max_seq_length\" should be adjusted to make SentenceTransformer model works properly and to be easy-to-understand\n          + Original PhoBERT-base-v2 from VinAI expects input of 256 tokens, which is its maximum sequence length\n      \n    - There are two ways to create new SentenceTransformer object, see: https://sbert.net/docs/sentence_transformer/usage/custom_models.html#structure-of-sentence-transformer-models\n      \n\"\"\"\n\n## first way to create SentenceTransformer model\nmodel = SentenceTransformer(\"vinai/phobert-base-v2\")\nmodel.max_seq_length = 256                               # by default,'max_seq_length' does not match to model maximum sequence length\n\n## second way\n# from sentence_transformers import models, SentenceTransformer\n\n# # Define Transformer model with max_seq_length=256\n# transformer = models.Transformer(\"vinai/phobert-base-v2\", max_seq_length=256)\n\n# # Define pooling layer\n# pooling = models.Pooling(transformer.get_word_embedding_dimension(), pooling_mode=\"mean\")\n\n# # Create SentenceTransformer model with both modules\n# model = SentenceTransformer(modules=[transformer, pooling])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T17:24:04.656505Z","iopub.execute_input":"2025-01-27T17:24:04.656828Z","iopub.status.idle":"2025-01-27T17:24:13.599745Z","shell.execute_reply.started":"2025-01-27T17:24:04.656803Z","shell.execute_reply":"2025-01-27T17:24:13.598799Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# check whether model can truncate input to max_seq_length, if you get an error, recheck model initiation step\n# paragraph = pair_class_dataset['train'][0]['context']\n# model.encode(paragraph)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T17:24:13.601353Z","iopub.execute_input":"2025-01-27T17:24:13.601600Z","iopub.status.idle":"2025-01-27T17:24:13.605372Z","shell.execute_reply.started":"2025-01-27T17:24:13.601579Z","shell.execute_reply":"2025-01-27T17:24:13.604360Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loss functions\npair_class_loss = SoftmaxLoss(model, model.get_sentence_embedding_dimension(), num_labels=2)  # for Pair-Class\ntriplet_loss = MultipleNegativesRankingLoss(model)                                            # for Triplet\n\n# Mapping datasets to losses\nlosses = {\n    \"pair-class\": pair_class_loss,\n    \"triplet\": triplet_loss\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T17:24:13.607500Z","iopub.execute_input":"2025-01-27T17:24:13.607921Z","iopub.status.idle":"2025-01-27T17:24:13.702669Z","shell.execute_reply.started":"2025-01-27T17:24:13.607889Z","shell.execute_reply":"2025-01-27T17:24:13.702049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluator for Triplet\ndev_triplet_evaluator = TripletEvaluator(\n    anchors=triplet_dataset[\"valid\"][\"anchor\"],\n    positives=triplet_dataset[\"valid\"][\"positive\"],\n    negatives=triplet_dataset[\"valid\"][\"negative\"],\n    name=\"triplet-dev\"\n)\n\ntest_triplet_evaluator = TripletEvaluator(\n    anchors=triplet_dataset[\"test\"][\"anchor\"],\n    positives=triplet_dataset[\"test\"][\"positive\"],\n    negatives=triplet_dataset[\"test\"][\"negative\"],\n    name=\"triplet-test\"\n)\n\n# Evaluator for Pair-Class\ndev_pair_class_evaluator = BinaryClassificationEvaluator(\n    sentences1=pair_class_dataset[\"valid\"][\"question\"],\n    sentences2=pair_class_dataset[\"valid\"][\"context\"],\n    labels=pair_class_dataset[\"valid\"][\"label\"],\n    name=\"pair-class-dev\"\n)\n\ntest_pair_class_evaluator = BinaryClassificationEvaluator(\n    sentences1=pair_class_dataset[\"test\"][\"question\"],\n    sentences2=pair_class_dataset[\"test\"][\"context\"],\n    labels=pair_class_dataset[\"test\"][\"label\"],\n    name=\"pair-class-test\"\n)\n\n# Combine evaluators with SequentialEvaluator\ndev_evaluator = SequentialEvaluator([dev_triplet_evaluator, dev_pair_class_evaluator], main_score_function=lambda scores: np.average(scores))\ntest_evaluator = SequentialEvaluator([test_triplet_evaluator, test_pair_class_evaluator], main_score_function=lambda scores: np.average(scores))\n\n# Use evaluator for evaluating Validation/Testing set before training\ndev_evaluator(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T17:25:45.957438Z","iopub.execute_input":"2025-01-27T17:25:45.957821Z","iopub.status.idle":"2025-01-27T17:26:14.198063Z","shell.execute_reply.started":"2025-01-27T17:25:45.957790Z","shell.execute_reply":"2025-01-27T17:26:14.197341Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training arguments\n\n\"\"\"\n    Documentation:\n    1. SentenceTransformerTrainingArguments, see: https://sbert.net/docs/package_reference/sentence_transformer/training_args.html#\n       Note: SentenceTransformerTrainingArguments extends TrainingArguments with additional arguments specific to Sentence Transformers\n       \n    2. make a BatchSamplers/MultiDatasetBatchSamplers, see: https://sbert.net/docs/package_reference/sentence_transformer/sampler.html#\n    3. examples, see: https://sbert.net/docs/sentence_transformer/training_overview.html\n\"\"\"\n\nargs = SentenceTransformerTrainingArguments(\n    output_dir=\"finetuned model\",\n    \n    # Optional training parameters:\n    num_train_epochs=10,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    learning_rate=1e-5,\n    warmup_ratio=0.1,\n    fp16=True, \n    multi_dataset_batch_sampler=MultiDatasetBatchSamplers.PROPORTIONAL,\n    \n    # Optional tracking/debugging parameters:\n    eval_strategy=\"epoch\",\n    # eval_steps=100,\n    save_strategy=\"epoch\",\n    # save_steps=100,\n    save_total_limit=1,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_sequential_score\",  \n    greater_is_better=True,\n    logging_dir=\"logs\",\n    logging_strategy=\"epoch\",\n    # logging_steps=100,\n    report_to=\"none\"     \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T17:27:49.225891Z","iopub.execute_input":"2025-01-27T17:27:49.226231Z","iopub.status.idle":"2025-01-27T17:27:49.261014Z","shell.execute_reply.started":"2025-01-27T17:27:49.226209Z","shell.execute_reply":"2025-01-27T17:27:49.260342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 7. Create a trainer & train\n\n\"\"\"\n    Notice:\n        You can use an evaluator with or without an eval_dataset, and vice versa (document)\n\"\"\"\n\n# there is a bug here, EarlyStoppingCallback cannot find and track any metrics \n# early_stop = EarlyStoppingCallback(2)\n\ntrainer = SentenceTransformerTrainer(\n    model=model,\n    args=args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    loss=losses,\n    evaluator=dev_evaluator,  \n    # callbacks=[early_stop]\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T17:28:00.307871Z","iopub.execute_input":"2025-01-27T17:28:00.308153Z","iopub.status.idle":"2025-01-27T17:44:48.945593Z","shell.execute_reply.started":"2025-01-27T17:28:00.308132Z","shell.execute_reply":"2025-01-27T17:44:48.944752Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import glob\nimport os\n\n# Path to the folder\npath = '/kaggle/working/finetuned model/'\n\n# Get all directories starting with 'checkpoint'\ncheckpoint_dirs = glob.glob(os.path.join(path, 'checkpoint*'))\n\ntrainer_state_dir = os.path.join(checkpoint_dirs[0], 'trainer_state.json')\nprint(trainer_state_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T17:53:45.296710Z","iopub.execute_input":"2025-01-27T17:53:45.297105Z","iopub.status.idle":"2025-01-27T17:53:45.302521Z","shell.execute_reply.started":"2025-01-27T17:53:45.297076Z","shell.execute_reply":"2025-01-27T17:53:45.301822Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\nwith open(trainer_state_dir, \"r\") as f:\n    trainer_state = json.load(f)\n\ntrainer_state","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T17:54:33.031874Z","iopub.execute_input":"2025-01-27T17:54:33.032168Z","iopub.status.idle":"2025-01-27T17:54:33.038887Z","shell.execute_reply.started":"2025-01-27T17:54:33.032147Z","shell.execute_reply":"2025-01-27T17:54:33.038042Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dev_evaluator(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T17:54:58.699520Z","iopub.execute_input":"2025-01-27T17:54:58.699918Z","iopub.status.idle":"2025-01-27T17:55:29.829884Z","shell.execute_reply.started":"2025-01-27T17:54:58.699889Z","shell.execute_reply":"2025-01-27T17:55:29.828848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_evaluator(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-27T17:55:29.831305Z","iopub.execute_input":"2025-01-27T17:55:29.831539Z","iopub.status.idle":"2025-01-27T17:56:00.788536Z","shell.execute_reply.started":"2025-01-27T17:55:29.831519Z","shell.execute_reply":"2025-01-27T17:56:00.787815Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Several mistakes**\n\n1. **with eval_dataset and dev evaluator**, KeyError: \"The metric_for_best_model training argument is set to 'eval_loss', which is not found in the evaluation metrics. The available evaluation metrics are: ['eval_pair-class_loss', 'eval_triplet-dev_cosine_accuracy', 'eval_pair-class-dev_cosine_accuracy', 'eval_pair-class-dev_cosine_accuracy_threshold', 'eval_pair-class-dev_cosine_f1', 'eval_pair-class-dev_cosine_f1_threshold', 'eval_pair-class-dev_cosine_precision', 'eval_pair-class-dev_cosine_recall', 'eval_pair-class-dev_cosine_ap', 'eval_sequential_score', 'eval_triplet_loss']. Consider changing the metric_for_best_model via the TrainingArguments.\"\n\n2. **with eval_dataset and without dev evaluator**, KeyError: \"The `metric_for_best_model` training argument is set to 'eval_sequential_score', which is not found in the evaluation metrics. The available evaluation metrics are: ['eval_pair-class_loss', 'eval_triplet_loss']. Consider changing the `metric_for_best_model` via the TrainingArguments.\"\n\n   after training, losses only have `Pair-class Loss` and `Triplet Loss` (have no `val_loss`)\n\n3. early stopping required metric_for_best_model, but did not find eval_sequential_score so early stopping is disabled.\n\n   *This a bug here, EarlyStoppingCallback cannot find and track any metrics even you implement both cases above (1 and 2)*\n\n5. ValueError: You have set `args.eval_strategy` to epoch but you didn't pass an `eval_dataset` to `Trainer`. Either set `args.eval_strategy` to `no` or pass an `eval_dataset`.\n\n","metadata":{}}]}